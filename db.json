{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"35968892d14b2bfeff23a41cb719da7b71c70fb8","modified":1527501862066},{"_id":"themes/next/README.md","hash":"950ca6e9c0fa607d290a5b1fd883df44725b36b2","modified":1526968940926},{"_id":"themes/next/_config.yml","hash":"864c5824d4e45322a069a568f0e1900948ed4571","modified":1526968940927},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1526968940936},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1526968940925},{"_id":"themes/next/bower.json","hash":"7d7938f9da896fe710aa0e9120140e528bf058df","modified":1526968940936},{"_id":"themes/next/README.cn.md","hash":"6d9177e7dad87e6129760e4b559bd3f7a15429d7","modified":1526968940926},{"_id":"source/_posts/2017-08-24-MyFirstPost.md","hash":"46ccf0019a24fc795671591e8ff51ba7d44d0d6e","modified":1526968940712},{"_id":"source/_posts/2018-05-28-CS231n106.md","hash":"50400df48b1ffe2e1d64981272ef6f7ae0f112c2","modified":1527501651723},{"_id":"themes/next/package.json","hash":"193dad6f59a588908fac082cc46fe067dac1b84d","modified":1526968941039},{"_id":"themes/next/languages/de.yml","hash":"98aa551443b2a61a74b6f2a218635da6d2f6cf57","modified":1526968940937},{"_id":"themes/next/languages/default.yml","hash":"c0b90d66772e79585cd26a81694ad69c16312d6b","modified":1526968940938},{"_id":"themes/next/languages/en.yml","hash":"c0b90d66772e79585cd26a81694ad69c16312d6b","modified":1526968940939},{"_id":"source/_drafts/hello-world.md","hash":"029f91fccbe8f87c0f3ea10c4042300d2fa7edc0","modified":1526968940712},{"_id":"themes/next/languages/id.yml","hash":"f8b57daac2e50ace9a6d5051b17208af8139c2ae","modified":1526968940940},{"_id":"themes/next/languages/fr-FR.yml","hash":"a14d051bbec26cfcae358bdcf1acf62a35fb1a45","modified":1526968940940},{"_id":"themes/next/languages/ja.yml","hash":"0c99ba4ba7d36c43d002342611d2c656ef498582","modified":1526968940942},{"_id":"themes/next/languages/ko.yml","hash":"043951e82997131dd8be40ff2093ef36849ba725","modified":1526968940943},{"_id":"themes/next/languages/pt-BR.yml","hash":"91584764104ef29293117375fc010b1bdbe9aff6","modified":1526968940943},{"_id":"themes/next/languages/pt.yml","hash":"dfd0b8574177346b78cab29db055fbc44ac309dc","modified":1526968940944},{"_id":"themes/next/languages/ru.yml","hash":"98dd9b6ddd88400a7b02cd7e8adb41e7b842bf57","modified":1526968940945},{"_id":"themes/next/languages/zh-Hans.yml","hash":"c1255b722fc5fdecf1852c3b592edfea9dbb554c","modified":1526968940945},{"_id":"themes/next/languages/zh-tw.yml","hash":"562141bfe450432131af012baa262a3de79a50bc","modified":1526968940946},{"_id":"themes/next/languages/zh-hk.yml","hash":"e8072846fd43beadbae394e30a49aa5c92a0a53b","modified":1526968940946},{"_id":"themes/next/layout/_layout.swig","hash":"37eddbe3ba9d71acf4710c20145cc09f722d2b6f","modified":1526968940948},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1526968941036},{"_id":"themes/next/layout/page.swig","hash":"37c874cd720acf0eda8d26e063278f2b6ae8d3a6","modified":1526968941036},{"_id":"themes/next/layout/archive.swig","hash":"3aa091e5f7fe1148206a2c616e9ad9ba797e9665","modified":1526968941035},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1526968941035},{"_id":"themes/next/scripts/merge-configs.js","hash":"13c8b3a2d9fce06c2488820d9248d190c8100e0a","modified":1526968941039},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1526968941040},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1526968941038},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1526968941038},{"_id":"themes/next/layout/post.swig","hash":"2d5f8d7f0a96b611e2d5a5e4d111fc17726a990f","modified":1526968941037},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1526968941709},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1526968941447},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1526968940947},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1526968940948},{"_id":"themes/next/layout/_partials/footer.swig","hash":"fb02c81273d5897ebb98b50f4c10f7edc34f9240","modified":1526968940961},{"_id":"themes/next/layout/_partials/comments.swig","hash":"010ef8c42d2e1a95abc60caf757293ca8eb4a68b","modified":1526968940961},{"_id":"themes/next/layout/_partials/head.swig","hash":"45777e38bed15b3b865cb7fba5a095478d744cc7","modified":1526968940978},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1526968940980},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1526968940980},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1526968940981},{"_id":"themes/next/layout/_partials/header.swig","hash":"714d32f6f04a7400b47bbd7fbfa008fec672b894","modified":1526968940980},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1526968940949},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"53d4f83b2b7fb4387dfc9fe81519abd56fbce4ae","modified":1526968940949},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1526968941710},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1526968941710},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1526968940960},{"_id":"themes/next/layout/_macro/post.swig","hash":"767e1d5503ecce85f577c8fb673a3503b65484ce","modified":1526968940950},{"_id":"themes/next/layout/_macro/reward.swig","hash":"5d5f70deb6074cb4dd0438463e14ccf89213c282","modified":1526968940959},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"dec65ee101231abbd9ef663e92f587d97d47c625","modified":1526968940959},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1526968941028},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1526968941028},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1526968941030},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1526968941028},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1526968940997},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1526968940997},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1526968941029},{"_id":"themes/next/scripts/tags/button.js","hash":"62e6dbeb53d07627a048132c79630b45d9a8f2cc","modified":1526968941045},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1526968941045},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1526968941029},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1526968941046},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1526968941046},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1526968941267},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1526968941267},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1526968941267},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1526968941268},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1526968941268},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"9baf90f7c40b3b10f288e9268c3191e895890cea","modified":1526968941005},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1526968941446},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1526968941448},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1526968941451},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1526968941453},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1526968941449},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1526968941452},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1526968941453},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1526968941451},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1526968941454},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1526968941454},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1526968941453},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1526968941454},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1526968941452},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1526968940999},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1526968940999},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1526968941310},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1526968941310},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1526968941312},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1526968941438},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1526968941442},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1526968941455},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1526968940979},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1526968940981},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1526968940982},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1526968940982},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1526968940979},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1526968940983},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1526968940983},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1526968941006},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1526968940984},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"fd65b0d38d4a8b8306de815c48caad20b84ba4cb","modified":1526968940989},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1526968941009},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1526968941010},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1526968941010},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1526968941011},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1526968941011},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1526968941012},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1526968941012},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1526968941448},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1526968941007},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1526968941010},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1526968941012},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1526968941013},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"576e716893153a855eaf6d136fad7cb6d4065e09","modified":1526968941020},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1526968941014},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"9f4ed36c73e890909b8ebbe601fb60e13d048288","modified":1526968941020},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1526968941021},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1526968941015},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1526968941031},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1526968941014},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1526968941019},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1526968941035},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1526968941020},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1526968940999},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1526968941003},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1526968940998},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1526968941031},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1526968941034},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1526968941309},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1526968941310},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"c8d35a6b9e3bff6d8fdb66de853065af9d37562d","modified":1526968941438},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1526968941311},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"6359c84aaa02c90be60b22abe638b737ddd69c9c","modified":1526968941438},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1526968941456},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"6117f97b4984b8e33f21c726132da64ba678e4ed","modified":1526968941457},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"cfee25d790e4f9b7d57f0dc7e2ea9c1649f08f11","modified":1526968941441},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1526968941456},{"_id":"themes/next/source/css/_variables/base.styl","hash":"d477196c5699c8261b08e993a77ef67054d86166","modified":1526968941442},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1526968941457},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1526968941458},{"_id":"themes/next/source/js/src/motion.js","hash":"dc0365b2fb315a8b43d3ef19b59d3a82a366fcc1","modified":1526968941460},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1526968941459},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1526968941461},{"_id":"themes/next/source/js/src/post-details.js","hash":"0693695a9512641daff63d99da772625a058ab18","modified":1526968941460},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1526968941311},{"_id":"themes/next/source/js/src/utils.js","hash":"2917c39c75b14b6dab7e1c46ab4d87b4df9fcd5d","modified":1526968941462},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1526968941461},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1526968941513},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1526968941550},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1526968941555},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1526968941554},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1526968941555},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1526968941544},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1526968941509},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1526968941550},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1526968941587},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1526968941548},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1526968941545},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1526968941589},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1526968941591},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1526968941592},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1526968941588},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1526968941592},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1526968941545},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1526968941593},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1526968941593},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"7fd2f3e2773555392ef40df40cae3bedb884f17a","modified":1526968941516},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1526968941622},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1526968941622},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1526968941623},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1526968941624},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1526968941623},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1526968941624},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1526968941625},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1526968941623},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1526968941626},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1526968941585},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1526968941626},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1526968941625},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1526968941628},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1526968941627},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1526968941628},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1526968941658},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1526968941659},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1526968941629},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1526968941707},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1526968941708},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1526968941708},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1526968941586},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1526968941031},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"d026c8489f66ab6c12ad04bd37f1d5b6f2f3f0d1","modified":1526968941270},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1526968941030},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"0dfb4b3ba3180d7285e66f270e1d3fa0f132c3d2","modified":1526968941271},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1526968941272},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1526968941272},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1526968941282},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1526968941295},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1526968941271},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"a9c6355d6516af2e13254ec89e33e5b7dcf8ceb4","modified":1526968941306},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1526968941306},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1526968941308},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"86b6fd7f1b1be3ae98f8af6b23a6b1299c670ce9","modified":1526968941308},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1526968941309},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1526968941320},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1526968941318},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1526968941319},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"f2030fa436c47791d1a42358cc0ef6f9809f212c","modified":1526968941305},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1526968941425},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1526968941426},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"bc8c388553bbcf95897459a466ba35bffd5ec5f0","modified":1526968941317},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1526968941430},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1526968941430},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"82bbaa6322764779a1ac2e2c8390ce901c7972e2","modified":1526968941431},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1526968941432},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1526968941432},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1526968941434},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1526968941308},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1526968941436},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1526968941434},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"f00d0a9ff02f6814011e0b613a2d9020911b5c58","modified":1526968941436},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1526968941437},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"79da92119bc246fe05d1626ac98426a83ec90a94","modified":1526968941461},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"fda14bc35be2e1b332809b55b3d07155a833dbf4","modified":1526968941426},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1526968941426},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"0af5a9322156c4c21d3c7d38f5ee48de5286f523","modified":1526968941434},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1526968941509},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1526968941517},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1526968941518},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1526968941518},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1526968941526},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1526968941476},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1526968941527},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1526968941527},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1526968941543},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1526968941478},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1526968941544},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1526968941565},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1526968941556},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1526968941543},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1526968941549},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1526968941549},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1526968941657},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1526968941657},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1526968941477},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1526968941583},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1526968941584},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1526968941274},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1526968941274},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1526968941275},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1526968941276},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1526968941277},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1526968941556},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"7778920dd105fa4de3a7ab206eeba30b1a7bac45","modified":1526968941279},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1526968941280},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1526968941280},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1526968941281},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1526968941282},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"beccb53dcd658136fb91a0c5678dea8f37d6e0b6","modified":1526968941284},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1526968941284},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1526968941285},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1526968941286},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"740d37f428b8f4574a76fc95cc25e50e0565f45e","modified":1526968941277},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1526968941287},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1526968941276},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"ee554b1031ef0070a5916477939021800e3c9d27","modified":1526968941288},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1526968941288},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1526968941288},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1526968941289},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"88c7d75646b66b168213190ee4cd874609afd5e3","modified":1526968941286},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1526968941289},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"08a500b2984f109b751f3697ca33172d1340591a","modified":1526968941290},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"e6680feea343cecbdde8d643c777d689742abc28","modified":1526968941290},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1526968941273},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"65a64d5662637b66e2f039a5f58217afe7a6e800","modified":1526968941291},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1526968941292},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"963105a531403d7aad6d9e5e23e3bfabb8ec065a","modified":1526968941289},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1526968941291},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1526968941293},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1526968941292},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1526968941287},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1526968941278},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1526968941294},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"57d2c8a060f5e4e1a0aef9aae11a0016cf7ac5ba","modified":1526968941294},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1526968941301},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1526968941301},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1526968941302},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1526968941302},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1526968941303},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1526968941303},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1526968941304},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"aeff0e6e23725e8baea27c890ccbbf466024f767","modified":1526968941304},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1526968941293},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1526968941296},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"b8969e1654eec89a0fd10d88b337fee9cb03cd44","modified":1526968941296},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1526968941298},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1526968941296},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"45df0cf4c97b47e05573bcd41028ee50f3fdf432","modified":1526968941299},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1526968941295},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1526968941300},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1526968941300},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1526968941428},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1526968941429},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1526968941433},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1526968941463},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"77c92a449ce84d558d26d052681f2e0dd77c70c9","modified":1526968941294},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1526968941464},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1526968941476},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1526968941528},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1526968941528},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1526968941541},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1526968941541},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1526968941542},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1526968941542},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1526968941566},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1526968941582},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1526968941660},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1526968941567},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1526968941512},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1526968941298},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1526968941299},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1526968941463},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1526968941655},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1526968941580},{"_id":"public/2017/08/24/MyFirstPost/index.html","hash":"c6a363f4418546bfe207f2bad868ddd7dcc5632a","modified":1527501664017},{"_id":"public/archives/index.html","hash":"c0802273c49fca746c98cc82121ddb0306c2f7eb","modified":1527501664016},{"_id":"public/archives/2017/08/index.html","hash":"6771f132c4dc56853fd480583ba51c276d8767f1","modified":1527501664018},{"_id":"public/archives/2017/index.html","hash":"69fe1b0119da83596297563936d3a274edf3d30e","modified":1527501664018},{"_id":"public/index.html","hash":"a596da7c5d6b05d44eb9e219eb6a914d9ee988b4","modified":1527501664018},{"_id":"public/categories/essay/index.html","hash":"dd9f0a34f9c9c40d7229688b8486f3b108031d4a","modified":1527501664018},{"_id":"public/tags/study/index.html","hash":"094ee1cdb973a39c4e359155c1ba317d52a312da","modified":1527501664018},{"_id":"public/CNAME","hash":"35968892d14b2bfeff23a41cb719da7b71c70fb8","modified":1527501871415},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1527501541607},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1527501541607},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1527501541607},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1527501541607},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1527501541607},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1527501541607},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1527501541607},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1527501541608},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1527501541608},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1527501541608},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1527501541608},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1527501541608},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1527501541608},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1527501541608},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1527501541608},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1527501541608},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1527501542754},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1527501542754},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1527501542763},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1527501542763},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1527501542763},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1527501542763},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1527501542763},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1527501542763},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1527501542763},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1527501542763},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1527501542763},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1527501542763},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1527501542779},{"_id":"public/js/src/bootstrap.js","hash":"6117f97b4984b8e33f21c726132da64ba678e4ed","modified":1527501542780},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1527501542796},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1527501542796},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1527501542796},{"_id":"public/js/src/motion.js","hash":"dc0365b2fb315a8b43d3ef19b59d3a82a366fcc1","modified":1527501542796},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1527501542796},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1527501542796},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1527501542796},{"_id":"public/js/src/post-details.js","hash":"0693695a9512641daff63d99da772625a058ab18","modified":1527501542796},{"_id":"public/js/src/utils.js","hash":"2917c39c75b14b6dab7e1c46ab4d87b4df9fcd5d","modified":1527501542796},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1527501542796},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1527501542796},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1527501542796},{"_id":"public/lib/fastclick/README.html","hash":"da3c74d484c73cc7df565e8abbfa4d6a5a18d4da","modified":1527501542797},{"_id":"public/lib/jquery_lazyload/README.html","hash":"bde24335f6bc09d8801c0dcd7274f71b466552bd","modified":1527501542797},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1527501542797},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1527501542797},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"a6358170d346af13b1452ac157b60505bec7015c","modified":1527501542797},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1527501542797},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1527501542797},{"_id":"public/css/main.css","hash":"3483a65ee969b15cc86caef3177b5bb46ff7b0a0","modified":1527501542797},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1527501542797},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1527501542797},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1527501542803},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1527501542804},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1527501542804},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1527501542804},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1527501542804},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1527501542804},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"7fd2f3e2773555392ef40df40cae3bedb884f17a","modified":1527501542804},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1527501542804},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1527501542804},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1527501542804},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1527501542804},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1527501542804},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1527501542804},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1527501542804},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1527501542804},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1527501542804},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1527501542804},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1527501542804},{"_id":"public/js/src/schemes/pisces.js","hash":"79da92119bc246fe05d1626ac98426a83ec90a94","modified":1527501542804},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1527501542804},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1527501542804},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1527501542804},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1527501542804},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1527501542804},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1527501542804},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1527501542804},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1527501542804},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1527501542804},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1527501542804},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1527501542805},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1527501542805},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1527501542805},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1527501542806},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1527501542806},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1527501542806},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1527501542806},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1527501542806},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1527501542806},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1527501542807},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1527501542807},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1527501542807},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1527501542807},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1527501542807},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1527501542807},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1527501542807},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1527501542807},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1527501542808},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1527501542808},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1527501542831},{"_id":"public/2018/01/01/CS231n106/index.html","hash":"ed044def697b40348c38041f4f722ea1317a7ca8","modified":1527501664018},{"_id":"public/archives/2018/index.html","hash":"4f029d91773c34a40fb1e8da5b7053e873c99813","modified":1527501664019},{"_id":"public/archives/2018/01/index.html","hash":"528dec44c5db788d86c57148705b631947938a2a","modified":1527501664019},{"_id":"public/tags/Machine-Learning/index.html","hash":"969de00c6b512a6fb44d442c450552d9fcdf5c5c","modified":1527501664019},{"_id":"public/tags/Deep-Learning/index.html","hash":"fdb8d955350bbb46a33a54eb90263a56a72707df","modified":1527501664019},{"_id":"public/tags/CS231n/index.html","hash":"2f330c868423b65e3cf2608f3b9d21666a68c2b5","modified":1527501664019},{"_id":"public/categories/CS231n/index.html","hash":"9ac12afb604247c7a784b3497d5c35761c8026e9","modified":1527501664020}],"Category":[{"name":"essay","_id":"cjhq2z7r60002p8vjzqpx8uu8"},{"name":"CS231n","_id":"cjhq31ucl0001m0vjpeexd1je"}],"Data":[],"Page":[],"Post":[{"title":"MyFirstPost","date":"2017-08-24T06:59:35.000Z","_content":"\n# 这个人很懒，什么也没有留下。\n* 恩\n* 是的\n* 没错\n> 哈哈哈\n","source":"_posts/2017-08-24-MyFirstPost.md","raw":"---\ntitle: MyFirstPost\ntags:\n  - study\ncategories:\n  - essay\ndate: 2017-08-24 14:59:35\n---\n\n# 这个人很懒，什么也没有留下。\n* 恩\n* 是的\n* 没错\n> 哈哈哈\n","slug":"MyFirstPost","published":1,"updated":"2018-05-22T06:02:20.712Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhq2z7qr0000p8vjfzvnel5l","content":"<h1 id=\"这个人很懒，什么也没有留下。\"><a href=\"#这个人很懒，什么也没有留下。\" class=\"headerlink\" title=\"这个人很懒，什么也没有留下。\"></a>这个人很懒，什么也没有留下。</h1><ul>\n<li>恩</li>\n<li>是的</li>\n<li>没错<blockquote>\n<p>哈哈哈</p>\n</blockquote>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"这个人很懒，什么也没有留下。\"><a href=\"#这个人很懒，什么也没有留下。\" class=\"headerlink\" title=\"这个人很懒，什么也没有留下。\"></a>这个人很懒，什么也没有留下。</h1><ul>\n<li>恩</li>\n<li>是的</li>\n<li>没错<blockquote>\n<p>哈哈哈</p>\n</blockquote>\n</li>\n</ul>\n"},{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","source":"_drafts/hello-world.md","raw":"---\ntitle: Hello World\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","slug":"hello-world","published":0,"date":"2018-05-22T06:02:20.711Z","updated":"2018-05-22T06:02:20.712Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhq2z7r10001p8vj2abufycq","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"external\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"external\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"external\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"external\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"external\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo server</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"external\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"external\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo deploy</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"external\">Deployment</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"external\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"external\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"external\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"external\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"external\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo server</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"external\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"external\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo deploy</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"external\">Deployment</a></p>\n"},{"title":"CS231n 2018 课程笔记 模块一 06","date":"2018-01-01T14:00:00.000Z","description":null,"_content":"\n[神经网络 第2部分：设置Data和Loss](http://cs231n.github.io/neural-networks-2/)\n----------\n这一部分主要讨论神经网络中一些数据的设置原则，包括：\n\n1. **数据X的预处理**\n2. **权值W的初始化**\n3. **正则化**\n4. **损失函数Loss的选择**\n\n## 1.数据预处理 ##\n\n### 0均值化 ###\n**0均值化**是将数据调整为以0为中心的处理。\n\n最常见的数据预处理，将数据Xi中每一维的数据都减去这一维的均值，代码为：`X -= np.mean(X, axis = 0)`。\n\n对于图片数据来说，因为X中的值都在0与255之间，可以直接减去整个整个X的均值，代码为：`X -= np.mean(X)`。\n\n### 标准化 ###\n**标准化**是将数据按比例缩放，使之落入一个小的特定区间。\n\n一种方法是将已经0均值化的数据除以它的标准差，代码为：`X /= np.std(X, axis = 0)`，这个处理将数据分布调整到-1和1之间。\n\n标准化只对每一个维度范围不一样数据有意义，对图片这种每一个像素值都在0到255的数据，不是必须的处理。\n\n![](http://cs231n.github.io/assets/nn2/prepro1.jpeg)\n**左图**是原始数据， **中图**是0均值化后的数据， **右图**为标准化后的数据。\n\n### 主成份分析(PCA) ###\n**主成分分析**主要用于数据降维，保留数据的主要特征。\n\nPCA的处理流程为：\n\n1. 对数据X进行0均值化\n2. 计算X的协方差矩阵\n3. 对协方差矩阵进行奇异值分解（SVD）\n4. 使用特征矩阵对数据X进行降维\n\n具体代码大致如下：\n\t\n    # 假设X的shape为 N by D\n    X -= np.mean(X, axis = 0) \t\t\t# 0均值化（必须）\n    cov = np.dot(X.T, X) / X.shape[0] \t# 计算协方差矩阵\n\tU,S,V = np.linalg.svd(cov) \t\t\t# 奇异值分解，S为奇异向量\n\tXrot_reduced = np.dot(X, U[:,:144]) # 将X降到144维\n\n矩阵U的列是X的标准正交的特征向量，可以把他们看作基向量。并且这些特征向量已经按特征值从大到小排序，我们只需要取指定的前n个特征向量（上述代码n取144）并将X映射过去，就能将X降为相应的n维数据（即Xi由D维降到n维）。\n\n和PCA类似，还有一种预处理**白化**，它是将X映射到完整的U上并进行标准化（归一化），代码如下：\n\n\tXrot = np.dot(X, U) # decorrelate the data\n\tXwhite = Xrot / np.sqrt(S + 1e-5) #加1e-5为了防止除0\n\n白化有一个缺点，它将所有特征都变得同样重要，这样会大幅扩大噪声。\n\n![](http://cs231n.github.io/assets/nn2/prepro2.jpeg)\n**左图**是原始数据， **中图**是投影到U上后的数据， **右图**为白化后的数据。\n\n----------\n\n![](http://cs231n.github.io/assets/nn2/cifar10pca.jpeg)\n上述是用CIFAR-10的图片做实验进行PCA和白化，从左到右：\n\n1. 原始图片，3072维（32像素宽，32像素高，3通道）\n2. U中的前144个特征向量，即`U[:,:144]`,其中每一列表示为一张图片\n3. PCA降维后还原的图片，代码为`Xrot.dot(U.T[:144,:])`，3072维\n4. 白化后的图片，低频部分被忽略，高频部分被放大\n\n### 小结 ###\n**在CNN中必要的预处理是0均值化，注意0均值化对于训练集、验证集和测试集都是减训练集的均值。**\n\n## 2.权值初始化 ##\n在训练神经网络之前，我们需要初始化权值矩阵W，而W取什么值是需要考虑的问题。\n\n### 0值初始化 ###\n将权值矩阵全部初始化为0是一个误区，如果每个神经元计算出相同的输出，在BP时也会计算出同样的梯度。另外，对于使用ReLU作为激活函数的隐层，输出为0且BP时梯度也都为0，这意味着所有非输入层神经元都死了，学习失败。\n\n### 随机小数值初始化 ###\n我们还是希望用接近0的小数值来初始化权值W，一般采用高斯分布的随机数，代码为`W = 0.01* np.random.randn(D,H)`，W的均值为0。**注意不能用太小的值来初始化W，过小的W会使BP时计算的梯度太小而导致梯度消失。**\n\n**用1/sqrt(n)来校正方差**。上述方法的一个问题随机初始化的神经元的输出的方差随着输入的增加而增加，所以我们将权值除以相应神经元的输入个数（证明参见[原文](http://cs231n.github.io/neural-networks-2/)），网络中的所有神经元都会有相同的输出分布，代码为：`w = np.random.randn(n) / sqrt(n)`。近期还有[研究](https://arxiv.org/abs/1502.01852)表明在特定的情况下ReLu神经元建议用`w = np.random.randn(n) / sqrt(2.0/n)`作为初始权值。\n\n### Bias初始化 ###\n还记得Bias吗？Bias一般初始化为0，实践证明初始化为0.01之类的有时结果很糟。\n\n### 小结 ###\n**建议使用ReLu激活并使用`w = np.random.randn(n) / sqrt(2.0/n)`进行权值初始化。**\n\n**另外，最近一项研究可以减轻很多神经网络初始化带来的麻烦，具体内容见[Batch Normalization](https://arxiv.org/abs/1502.03167)。**\n\n## 3.正则化 ##\n正则化是一种惩罚模型复杂性的方法，一般用来控制权值W的大小和分布，防止网络训练过拟合。\n\n### L2范数 ###\nL2范数是最常用的正则化处理，Loss函数加上\\\\(\\frac{1}{2} \\lambda w^2\\\\)可以直接对权值\\\\(w\\\\)进行平方量级的惩罚。系数之所以为\\\\(\\frac{1}{2}\\\\)，是因为\\\\(\\frac{1}{2} \\lambda w^2\\\\)对于\\\\(w\\\\)的梯度可以简单表示为\\\\(\\lambda w\\\\)。L2范数对陡峭的权值向量进行很重的惩罚并有利于获得比较分散的权值向量。\n\n### L1范数 ###\nL1范数也是相比较常用的正则化处理，Loss函数加上\\\\(\\lambda  \\mid w \\mid\\\\)一样可以对权值\\\\(w\\\\)进行惩罚，并有利于获得比较稀疏的权值向量。使用L2范数一般会获得比L1范数更分散且值较小的权值向量，所以L2范数一般比L1范数性能好。\n\n### Max norm constraints ###\nMax norm constraints是一种约束权值向量绝对值上限的方式，并用投影梯度下降确保这个约束。在实践中，像往常一样更新参数，然后强制权值\\\\(w\\\\)满足\\\\(\\Vert w \\Vert_2 < c\\\\)，\\\\(c\\\\)一般为3或4。这种方法的性质是即使学习率设置很大也不会发生数值爆炸，因为参数更新永远在一定范围内。\n\n### 随机失活（Dropout） ###\n随机失活是一种Srivastava在[Dropout: A Simple Way to Prevent Neural Networks from Overfitting](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)中提出的简单且非常有效的正则化方法，它对其它方法（L1，L2，Maxnorm）进行补充。在训练时，随机失活保持神经元以概率\\\\(p\\\\)（超参数）激活,否则让其死亡（设为0）。\n\n![](http://cs231n.github.io/assets/nn2/dropout.jpeg)\n\n上图是从[论文](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)中摘下来的，它描述了这种思想。在训练中，随机失活可以理解为从全连接的神经网络中进行取样，在输入数据的基础上只更新被取样的网络。在测试的时候，不采用随机失活，可以理解为是对所有子网络的指数级ensemble（将在下一部分介绍）作一个平均预测。\n\nVanilla的一个三层网络的随机失活代码实现如下：\n\t\n\t\"\"\" Vanilla Dropout: 这不是建议的实现方式 (具体的往下看) \"\"\"\n\t\n\tp = 0.5 # 随机失活的概率\n\t\n\tdef train_step(X):\n\t  \"\"\" X contains the data \"\"\"\n\t  \n\t  # forward pass for example 3-layer neural network\n\t  H1 = np.maximum(0, np.dot(W1, X) + b1)\n\t  U1 = np.random.rand(*H1.shape) < p # 第一隐层输出的失活掩码\n\t  H1 *= U1 # drop!\n\t  H2 = np.maximum(0, np.dot(W2, H1) + b2)\n\t  U2 = np.random.rand(*H2.shape) < p # 第二隐层输出的失活掩码\n\t  H2 *= U2 # drop!\n\t  out = np.dot(W3, H2) + b3\n\t  \n\t  # backward pass: compute gradients... (not shown)\n\t  # perform parameter update... (not shown)\n\t  \n\tdef predict(X):\n\t  # ensembled forward pass\n\t  H1 = np.maximum(0, np.dot(W1, X) + b1) * p # 将第一隐层输出缩放\n\t  H2 = np.maximum(0, np.dot(W2, H1) + b2) * p # 将第二隐层输出缩放\n\t  out = np.dot(W3, H2) + b3\n\n上述代码的train_step函数在第一个隐层和第二个隐层的输出上进行了两次随机失活，当然对输入层的输出X进行随机失活也是可以的。反向传播保持不变，但是当然不得不考虑正向生成的掩码U1和U2。（**如何考虑？**）\n\n关键是要注意预测函数`predict`并没有使用任何随机失活，但是将两个隐层的输出按比例\\\\(p\\\\)缩放了。这一点很重要，因为在测试阶段所有的神经元是看得到所有的输入的而训练阶段不是，所以我们希望测试阶段的输出和训练阶段的输出保持一致。\n\n为了不在关键的测试阶段缩放数据，一般采用**反向随机失活**（**inverted dropout**），即在训练阶段使用随机失活后就立即反向缩放数据来还原输出量，代码如下：\n\n\t\"\"\" \n\tInverted Dropout: 这才是建议的实现方式\n\t在训练阶段反向缩放数据，不用动测试阶段的代码。\n\t\"\"\"\n\t\n\tp = 0.5 # 随机失活的概率\n\t\n\tdef train_step(X):\n\t  # forward pass for example 3-layer neural network\n\t  H1 = np.maximum(0, np.dot(W1, X) + b1)\n\t  U1 = (np.random.rand(*H1.shape) < p) / p # 第一隐层失活，注意放大了1/p!\n\t  H1 *= U1 # drop!\n\t  H2 = np.maximum(0, np.dot(W2, H1) + b2)\n\t  U2 = (np.random.rand(*H2.shape) < p) / p # 第一隐层失活. 注意放大了1/p!\n\t  H2 *= U2 # drop!\n\t  out = np.dot(W3, H2) + b3\n\t  \n\t  # backward pass: compute gradients... (not shown)\n\t  # perform parameter update... (not shown)\n\t  \n\tdef predict(X):\n\t  # ensembled forward pass\n\t  H1 = np.maximum(0, np.dot(W1, X) + b1) # 这里没有缩放了！\n\t  H2 = np.maximum(0, np.dot(W2, H1) + b2) # 这里没有缩放了！\n\t  out = np.dot(W3, H2) + b3\n\n### 正向传递中的噪声 ###\n随机失活属于网络正向传递的随机行为中的一般方法中的一种，经过测试，通过这种方法噪声会被边缘化。[DropConnect](https://cs.nyu.edu/~wanli/dropc/)是这个方面的另一种方法，它在正向传递时用随机数的掩码代替随机失活中的0掩码。在CNN中有很多类似的方法，包括随机采样池化（stochastic pooling）等，将在后续章节介绍。\n\n### Bias正则化 ###\n还记得Bias吗？我们一般不正则化Bias，因为它不与数据交互。\n\n### 小结 ###\n**一般最最常用的正则化方式是单独使用L2范数，然后在每层使用\\\\(p = 0.5\\\\)的随机失活，\\\\(p\\\\)可以使用验证集调整。**\n\n## 4.损失函数（Loss functions） ##\n损失函数是一个监督学习的问题，用来衡量预测和真实标签的匹配度。整体的数据损失是每个样本损失的均值，\\\\(L = \\frac{1}{N} \\sum\\_i L\\_i\\\\)，N是训练样本数。我们将输出层的激活函数简写为\\\\(f = f(x_i; W)\\\\)，接下来我们讨论一些问题：\n\n### 分类 ###\n假设数据集中每个样本只有一个正确的标签，一个最常用的损失函数是SVM分类器使用的铰链损失（hinge loss）：\n$$L\\_i = \\sum\\_{j\\neq y\\_i} \\max(0, f\\_j - f\\_{y\\_i} + 1)$$\n有些报道称用平方铰链损失（squared hinge loss）\\\\(\\max(0, f\\_j - f\\_{y\\_i} + 1)^2\\\\)具有更好的性能。另一种常用的损失函数是Softmax分类器使用的交叉熵损失（cross-entropy loss）：\n$$L_i = -\\log\\left(\\frac{e^{f\\_{y\\_i}}}{ \\sum\\_j e^{f\\_j} }\\right)$$\n\n### 问题：大量的类别 ###\n当标签种类非常多（例如字典里的词数或者ImageNet中的22000个图片类别）时，可能需要用到分层Softmax(Hierarchical Softmax)。分层Softmax将所有类别标签分解到一棵二叉树中，每一个类别标签表示为树上的一条路径，详细的内容见将其[应用于Word2Vec的论文](https://arxiv.org/pdf/1310.4546.pdf)。\n\n### 属性分类 ###\n输出向量不是含有每个样本的单个的类别标签，而是含有每个样本中所具有的多个属性标签，比如说Instagram上的一张图片含有多个关键字。一种明智的做法是为每一个属性创建一个独立的二分类器：\n$$L\\_i = \\sum\\_j \\max(0, 1 - y\\_{ij} f\\_j)$$\n上式中\\\\(j\\\\)为属性种类，\\\\(y\\_{ij}\\\\)为标签，表示\\\\(i\\\\)样本是否具有\\\\(j\\\\)属性，取值为+1或-1。\\\\(f\\_j\\\\)为预测值，正值表示预测具有\\\\(j\\\\)属性，否则不具有\\\\(j\\\\)属性。\n\n另一种可选的方法是为每个属性单独的训练一个逻辑回归（logistic regression）分类器。一个二元逻辑回归分类器只拥有两个类别（0,1），然后计算类别1的概率：\n$$P(y = 1 \\mid x; w, b) = \\frac{1}{1 + e^{-(w^Tx +b)}} = \\sigma (w^Tx + b)$$\n因为类别1和类别0的概率之和为1，所以类别0的概率为\\\\(P(y = 0 \\mid x; w, b) = 1 - P(y = 1 \\mid x; w,b)\\\\)。当\\\\(\\sigma (w^Tx + b) > 0.5\\\\)或\\\\(w^Tx +b > 0\\\\)时样本为正例，即分类为1。损失函数为：\n$$L\\_i = - \\sum\\_j y\\_{ij} \\log(\\sigma(f\\_j)) + (1 - y\\_{ij}) \\log(1 - \\sigma(f\\_j))$$\n损失函数对\\\\(f\\\\)求导结果非常简单 \\\\(\\partial{L\\_i} / \\partial{f\\_j} = y\\_{ij} - \\sigma(f\\_j)\\\\)。\n\n### 回归（Regression） ###\n回归是预测连续实值的任务，比如预测房价。在这种任务中，损失函数一般计算预测值和实际值差值的L2范数平方或L1范数。使用L2范数平方的损失函数表示为：\n$$L\\_i = \\Vert f - y\\_i \\Vert\\_2^2$$\n之所以用L2范数平方是因为求梯度简单。**注意回归问题比分类问题难优化的多，处理回归问题应该最先考虑是否能转化为分类问题。**\n\n###小节###\n**在每类任务中采用最常用的损失函数**\n\n## 总结 ##\n- **对数据X进行0均值化处理**\n- **使用`w = np.random.randn(n) * sqrt(2.0/n)`初始化权值W，n为输入变量个数**\n- **使用L2范数正则化并采用反向随机失活**\n- **使用batch normalization**\n- **在每类任务中采用最常用的损失函数**\n\n----------\n© 2018 by 0ne.tech","source":"_posts/2018-05-28-CS231n106.md","raw":"---\ntitle: CS231n 2018 课程笔记 模块一 06 #文章標題\ndate: 2018-01-01 22:00:00 #文章生成時間\ncategories: \"CS231n\" #文章分類目錄 可以省略\ntags: #文章標籤 可以省略\n     - Machine Learning\n     - Deep Learning\n     - CS231n\ndescription: #你對本頁的描述 可以省略\n---\n\n[神经网络 第2部分：设置Data和Loss](http://cs231n.github.io/neural-networks-2/)\n----------\n这一部分主要讨论神经网络中一些数据的设置原则，包括：\n\n1. **数据X的预处理**\n2. **权值W的初始化**\n3. **正则化**\n4. **损失函数Loss的选择**\n\n## 1.数据预处理 ##\n\n### 0均值化 ###\n**0均值化**是将数据调整为以0为中心的处理。\n\n最常见的数据预处理，将数据Xi中每一维的数据都减去这一维的均值，代码为：`X -= np.mean(X, axis = 0)`。\n\n对于图片数据来说，因为X中的值都在0与255之间，可以直接减去整个整个X的均值，代码为：`X -= np.mean(X)`。\n\n### 标准化 ###\n**标准化**是将数据按比例缩放，使之落入一个小的特定区间。\n\n一种方法是将已经0均值化的数据除以它的标准差，代码为：`X /= np.std(X, axis = 0)`，这个处理将数据分布调整到-1和1之间。\n\n标准化只对每一个维度范围不一样数据有意义，对图片这种每一个像素值都在0到255的数据，不是必须的处理。\n\n![](http://cs231n.github.io/assets/nn2/prepro1.jpeg)\n**左图**是原始数据， **中图**是0均值化后的数据， **右图**为标准化后的数据。\n\n### 主成份分析(PCA) ###\n**主成分分析**主要用于数据降维，保留数据的主要特征。\n\nPCA的处理流程为：\n\n1. 对数据X进行0均值化\n2. 计算X的协方差矩阵\n3. 对协方差矩阵进行奇异值分解（SVD）\n4. 使用特征矩阵对数据X进行降维\n\n具体代码大致如下：\n\t\n    # 假设X的shape为 N by D\n    X -= np.mean(X, axis = 0) \t\t\t# 0均值化（必须）\n    cov = np.dot(X.T, X) / X.shape[0] \t# 计算协方差矩阵\n\tU,S,V = np.linalg.svd(cov) \t\t\t# 奇异值分解，S为奇异向量\n\tXrot_reduced = np.dot(X, U[:,:144]) # 将X降到144维\n\n矩阵U的列是X的标准正交的特征向量，可以把他们看作基向量。并且这些特征向量已经按特征值从大到小排序，我们只需要取指定的前n个特征向量（上述代码n取144）并将X映射过去，就能将X降为相应的n维数据（即Xi由D维降到n维）。\n\n和PCA类似，还有一种预处理**白化**，它是将X映射到完整的U上并进行标准化（归一化），代码如下：\n\n\tXrot = np.dot(X, U) # decorrelate the data\n\tXwhite = Xrot / np.sqrt(S + 1e-5) #加1e-5为了防止除0\n\n白化有一个缺点，它将所有特征都变得同样重要，这样会大幅扩大噪声。\n\n![](http://cs231n.github.io/assets/nn2/prepro2.jpeg)\n**左图**是原始数据， **中图**是投影到U上后的数据， **右图**为白化后的数据。\n\n----------\n\n![](http://cs231n.github.io/assets/nn2/cifar10pca.jpeg)\n上述是用CIFAR-10的图片做实验进行PCA和白化，从左到右：\n\n1. 原始图片，3072维（32像素宽，32像素高，3通道）\n2. U中的前144个特征向量，即`U[:,:144]`,其中每一列表示为一张图片\n3. PCA降维后还原的图片，代码为`Xrot.dot(U.T[:144,:])`，3072维\n4. 白化后的图片，低频部分被忽略，高频部分被放大\n\n### 小结 ###\n**在CNN中必要的预处理是0均值化，注意0均值化对于训练集、验证集和测试集都是减训练集的均值。**\n\n## 2.权值初始化 ##\n在训练神经网络之前，我们需要初始化权值矩阵W，而W取什么值是需要考虑的问题。\n\n### 0值初始化 ###\n将权值矩阵全部初始化为0是一个误区，如果每个神经元计算出相同的输出，在BP时也会计算出同样的梯度。另外，对于使用ReLU作为激活函数的隐层，输出为0且BP时梯度也都为0，这意味着所有非输入层神经元都死了，学习失败。\n\n### 随机小数值初始化 ###\n我们还是希望用接近0的小数值来初始化权值W，一般采用高斯分布的随机数，代码为`W = 0.01* np.random.randn(D,H)`，W的均值为0。**注意不能用太小的值来初始化W，过小的W会使BP时计算的梯度太小而导致梯度消失。**\n\n**用1/sqrt(n)来校正方差**。上述方法的一个问题随机初始化的神经元的输出的方差随着输入的增加而增加，所以我们将权值除以相应神经元的输入个数（证明参见[原文](http://cs231n.github.io/neural-networks-2/)），网络中的所有神经元都会有相同的输出分布，代码为：`w = np.random.randn(n) / sqrt(n)`。近期还有[研究](https://arxiv.org/abs/1502.01852)表明在特定的情况下ReLu神经元建议用`w = np.random.randn(n) / sqrt(2.0/n)`作为初始权值。\n\n### Bias初始化 ###\n还记得Bias吗？Bias一般初始化为0，实践证明初始化为0.01之类的有时结果很糟。\n\n### 小结 ###\n**建议使用ReLu激活并使用`w = np.random.randn(n) / sqrt(2.0/n)`进行权值初始化。**\n\n**另外，最近一项研究可以减轻很多神经网络初始化带来的麻烦，具体内容见[Batch Normalization](https://arxiv.org/abs/1502.03167)。**\n\n## 3.正则化 ##\n正则化是一种惩罚模型复杂性的方法，一般用来控制权值W的大小和分布，防止网络训练过拟合。\n\n### L2范数 ###\nL2范数是最常用的正则化处理，Loss函数加上\\\\(\\frac{1}{2} \\lambda w^2\\\\)可以直接对权值\\\\(w\\\\)进行平方量级的惩罚。系数之所以为\\\\(\\frac{1}{2}\\\\)，是因为\\\\(\\frac{1}{2} \\lambda w^2\\\\)对于\\\\(w\\\\)的梯度可以简单表示为\\\\(\\lambda w\\\\)。L2范数对陡峭的权值向量进行很重的惩罚并有利于获得比较分散的权值向量。\n\n### L1范数 ###\nL1范数也是相比较常用的正则化处理，Loss函数加上\\\\(\\lambda  \\mid w \\mid\\\\)一样可以对权值\\\\(w\\\\)进行惩罚，并有利于获得比较稀疏的权值向量。使用L2范数一般会获得比L1范数更分散且值较小的权值向量，所以L2范数一般比L1范数性能好。\n\n### Max norm constraints ###\nMax norm constraints是一种约束权值向量绝对值上限的方式，并用投影梯度下降确保这个约束。在实践中，像往常一样更新参数，然后强制权值\\\\(w\\\\)满足\\\\(\\Vert w \\Vert_2 < c\\\\)，\\\\(c\\\\)一般为3或4。这种方法的性质是即使学习率设置很大也不会发生数值爆炸，因为参数更新永远在一定范围内。\n\n### 随机失活（Dropout） ###\n随机失活是一种Srivastava在[Dropout: A Simple Way to Prevent Neural Networks from Overfitting](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)中提出的简单且非常有效的正则化方法，它对其它方法（L1，L2，Maxnorm）进行补充。在训练时，随机失活保持神经元以概率\\\\(p\\\\)（超参数）激活,否则让其死亡（设为0）。\n\n![](http://cs231n.github.io/assets/nn2/dropout.jpeg)\n\n上图是从[论文](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)中摘下来的，它描述了这种思想。在训练中，随机失活可以理解为从全连接的神经网络中进行取样，在输入数据的基础上只更新被取样的网络。在测试的时候，不采用随机失活，可以理解为是对所有子网络的指数级ensemble（将在下一部分介绍）作一个平均预测。\n\nVanilla的一个三层网络的随机失活代码实现如下：\n\t\n\t\"\"\" Vanilla Dropout: 这不是建议的实现方式 (具体的往下看) \"\"\"\n\t\n\tp = 0.5 # 随机失活的概率\n\t\n\tdef train_step(X):\n\t  \"\"\" X contains the data \"\"\"\n\t  \n\t  # forward pass for example 3-layer neural network\n\t  H1 = np.maximum(0, np.dot(W1, X) + b1)\n\t  U1 = np.random.rand(*H1.shape) < p # 第一隐层输出的失活掩码\n\t  H1 *= U1 # drop!\n\t  H2 = np.maximum(0, np.dot(W2, H1) + b2)\n\t  U2 = np.random.rand(*H2.shape) < p # 第二隐层输出的失活掩码\n\t  H2 *= U2 # drop!\n\t  out = np.dot(W3, H2) + b3\n\t  \n\t  # backward pass: compute gradients... (not shown)\n\t  # perform parameter update... (not shown)\n\t  \n\tdef predict(X):\n\t  # ensembled forward pass\n\t  H1 = np.maximum(0, np.dot(W1, X) + b1) * p # 将第一隐层输出缩放\n\t  H2 = np.maximum(0, np.dot(W2, H1) + b2) * p # 将第二隐层输出缩放\n\t  out = np.dot(W3, H2) + b3\n\n上述代码的train_step函数在第一个隐层和第二个隐层的输出上进行了两次随机失活，当然对输入层的输出X进行随机失活也是可以的。反向传播保持不变，但是当然不得不考虑正向生成的掩码U1和U2。（**如何考虑？**）\n\n关键是要注意预测函数`predict`并没有使用任何随机失活，但是将两个隐层的输出按比例\\\\(p\\\\)缩放了。这一点很重要，因为在测试阶段所有的神经元是看得到所有的输入的而训练阶段不是，所以我们希望测试阶段的输出和训练阶段的输出保持一致。\n\n为了不在关键的测试阶段缩放数据，一般采用**反向随机失活**（**inverted dropout**），即在训练阶段使用随机失活后就立即反向缩放数据来还原输出量，代码如下：\n\n\t\"\"\" \n\tInverted Dropout: 这才是建议的实现方式\n\t在训练阶段反向缩放数据，不用动测试阶段的代码。\n\t\"\"\"\n\t\n\tp = 0.5 # 随机失活的概率\n\t\n\tdef train_step(X):\n\t  # forward pass for example 3-layer neural network\n\t  H1 = np.maximum(0, np.dot(W1, X) + b1)\n\t  U1 = (np.random.rand(*H1.shape) < p) / p # 第一隐层失活，注意放大了1/p!\n\t  H1 *= U1 # drop!\n\t  H2 = np.maximum(0, np.dot(W2, H1) + b2)\n\t  U2 = (np.random.rand(*H2.shape) < p) / p # 第一隐层失活. 注意放大了1/p!\n\t  H2 *= U2 # drop!\n\t  out = np.dot(W3, H2) + b3\n\t  \n\t  # backward pass: compute gradients... (not shown)\n\t  # perform parameter update... (not shown)\n\t  \n\tdef predict(X):\n\t  # ensembled forward pass\n\t  H1 = np.maximum(0, np.dot(W1, X) + b1) # 这里没有缩放了！\n\t  H2 = np.maximum(0, np.dot(W2, H1) + b2) # 这里没有缩放了！\n\t  out = np.dot(W3, H2) + b3\n\n### 正向传递中的噪声 ###\n随机失活属于网络正向传递的随机行为中的一般方法中的一种，经过测试，通过这种方法噪声会被边缘化。[DropConnect](https://cs.nyu.edu/~wanli/dropc/)是这个方面的另一种方法，它在正向传递时用随机数的掩码代替随机失活中的0掩码。在CNN中有很多类似的方法，包括随机采样池化（stochastic pooling）等，将在后续章节介绍。\n\n### Bias正则化 ###\n还记得Bias吗？我们一般不正则化Bias，因为它不与数据交互。\n\n### 小结 ###\n**一般最最常用的正则化方式是单独使用L2范数，然后在每层使用\\\\(p = 0.5\\\\)的随机失活，\\\\(p\\\\)可以使用验证集调整。**\n\n## 4.损失函数（Loss functions） ##\n损失函数是一个监督学习的问题，用来衡量预测和真实标签的匹配度。整体的数据损失是每个样本损失的均值，\\\\(L = \\frac{1}{N} \\sum\\_i L\\_i\\\\)，N是训练样本数。我们将输出层的激活函数简写为\\\\(f = f(x_i; W)\\\\)，接下来我们讨论一些问题：\n\n### 分类 ###\n假设数据集中每个样本只有一个正确的标签，一个最常用的损失函数是SVM分类器使用的铰链损失（hinge loss）：\n$$L\\_i = \\sum\\_{j\\neq y\\_i} \\max(0, f\\_j - f\\_{y\\_i} + 1)$$\n有些报道称用平方铰链损失（squared hinge loss）\\\\(\\max(0, f\\_j - f\\_{y\\_i} + 1)^2\\\\)具有更好的性能。另一种常用的损失函数是Softmax分类器使用的交叉熵损失（cross-entropy loss）：\n$$L_i = -\\log\\left(\\frac{e^{f\\_{y\\_i}}}{ \\sum\\_j e^{f\\_j} }\\right)$$\n\n### 问题：大量的类别 ###\n当标签种类非常多（例如字典里的词数或者ImageNet中的22000个图片类别）时，可能需要用到分层Softmax(Hierarchical Softmax)。分层Softmax将所有类别标签分解到一棵二叉树中，每一个类别标签表示为树上的一条路径，详细的内容见将其[应用于Word2Vec的论文](https://arxiv.org/pdf/1310.4546.pdf)。\n\n### 属性分类 ###\n输出向量不是含有每个样本的单个的类别标签，而是含有每个样本中所具有的多个属性标签，比如说Instagram上的一张图片含有多个关键字。一种明智的做法是为每一个属性创建一个独立的二分类器：\n$$L\\_i = \\sum\\_j \\max(0, 1 - y\\_{ij} f\\_j)$$\n上式中\\\\(j\\\\)为属性种类，\\\\(y\\_{ij}\\\\)为标签，表示\\\\(i\\\\)样本是否具有\\\\(j\\\\)属性，取值为+1或-1。\\\\(f\\_j\\\\)为预测值，正值表示预测具有\\\\(j\\\\)属性，否则不具有\\\\(j\\\\)属性。\n\n另一种可选的方法是为每个属性单独的训练一个逻辑回归（logistic regression）分类器。一个二元逻辑回归分类器只拥有两个类别（0,1），然后计算类别1的概率：\n$$P(y = 1 \\mid x; w, b) = \\frac{1}{1 + e^{-(w^Tx +b)}} = \\sigma (w^Tx + b)$$\n因为类别1和类别0的概率之和为1，所以类别0的概率为\\\\(P(y = 0 \\mid x; w, b) = 1 - P(y = 1 \\mid x; w,b)\\\\)。当\\\\(\\sigma (w^Tx + b) > 0.5\\\\)或\\\\(w^Tx +b > 0\\\\)时样本为正例，即分类为1。损失函数为：\n$$L\\_i = - \\sum\\_j y\\_{ij} \\log(\\sigma(f\\_j)) + (1 - y\\_{ij}) \\log(1 - \\sigma(f\\_j))$$\n损失函数对\\\\(f\\\\)求导结果非常简单 \\\\(\\partial{L\\_i} / \\partial{f\\_j} = y\\_{ij} - \\sigma(f\\_j)\\\\)。\n\n### 回归（Regression） ###\n回归是预测连续实值的任务，比如预测房价。在这种任务中，损失函数一般计算预测值和实际值差值的L2范数平方或L1范数。使用L2范数平方的损失函数表示为：\n$$L\\_i = \\Vert f - y\\_i \\Vert\\_2^2$$\n之所以用L2范数平方是因为求梯度简单。**注意回归问题比分类问题难优化的多，处理回归问题应该最先考虑是否能转化为分类问题。**\n\n###小节###\n**在每类任务中采用最常用的损失函数**\n\n## 总结 ##\n- **对数据X进行0均值化处理**\n- **使用`w = np.random.randn(n) * sqrt(2.0/n)`初始化权值W，n为输入变量个数**\n- **使用L2范数正则化并采用反向随机失活**\n- **使用batch normalization**\n- **在每类任务中采用最常用的损失函数**\n\n----------\n© 2018 by 0ne.tech","slug":"CS231n106","published":1,"updated":"2018-05-28T10:00:51.723Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhq31uc40000m0vji7e5d6c7","content":"<h2 id=\"神经网络-第2部分：设置Data和Loss\"><a href=\"#神经网络-第2部分：设置Data和Loss\" class=\"headerlink\" title=\"神经网络 第2部分：设置Data和Loss\"></a><a href=\"http://cs231n.github.io/neural-networks-2/\" target=\"_blank\" rel=\"external\">神经网络 第2部分：设置Data和Loss</a></h2><p>这一部分主要讨论神经网络中一些数据的设置原则，包括：</p>\n<ol>\n<li><strong>数据X的预处理</strong></li>\n<li><strong>权值W的初始化</strong></li>\n<li><strong>正则化</strong></li>\n<li><strong>损失函数Loss的选择</strong></li>\n</ol>\n<h2 id=\"1-数据预处理\"><a href=\"#1-数据预处理\" class=\"headerlink\" title=\"1.数据预处理\"></a>1.数据预处理</h2><h3 id=\"0均值化\"><a href=\"#0均值化\" class=\"headerlink\" title=\"0均值化\"></a>0均值化</h3><p><strong>0均值化</strong>是将数据调整为以0为中心的处理。</p>\n<p>最常见的数据预处理，将数据Xi中每一维的数据都减去这一维的均值，代码为：<code>X -= np.mean(X, axis = 0)</code>。</p>\n<p>对于图片数据来说，因为X中的值都在0与255之间，可以直接减去整个整个X的均值，代码为：<code>X -= np.mean(X)</code>。</p>\n<h3 id=\"标准化\"><a href=\"#标准化\" class=\"headerlink\" title=\"标准化\"></a>标准化</h3><p><strong>标准化</strong>是将数据按比例缩放，使之落入一个小的特定区间。</p>\n<p>一种方法是将已经0均值化的数据除以它的标准差，代码为：<code>X /= np.std(X, axis = 0)</code>，这个处理将数据分布调整到-1和1之间。</p>\n<p>标准化只对每一个维度范围不一样数据有意义，对图片这种每一个像素值都在0到255的数据，不是必须的处理。</p>\n<p><img src=\"http://cs231n.github.io/assets/nn2/prepro1.jpeg\" alt=\"\"><br><strong>左图</strong>是原始数据， <strong>中图</strong>是0均值化后的数据， <strong>右图</strong>为标准化后的数据。</p>\n<h3 id=\"主成份分析-PCA\"><a href=\"#主成份分析-PCA\" class=\"headerlink\" title=\"主成份分析(PCA)\"></a>主成份分析(PCA)</h3><p><strong>主成分分析</strong>主要用于数据降维，保留数据的主要特征。</p>\n<p>PCA的处理流程为：</p>\n<ol>\n<li>对数据X进行0均值化</li>\n<li>计算X的协方差矩阵</li>\n<li>对协方差矩阵进行奇异值分解（SVD）</li>\n<li>使用特征矩阵对数据X进行降维</li>\n</ol>\n<p>具体代码大致如下：</p>\n<pre><code># 假设X的shape为 N by D\nX -= np.mean(X, axis = 0)             # 0均值化（必须）\ncov = np.dot(X.T, X) / X.shape[0]     # 计算协方差矩阵\nU,S,V = np.linalg.svd(cov)             # 奇异值分解，S为奇异向量\nXrot_reduced = np.dot(X, U[:,:144]) # 将X降到144维\n</code></pre><p>矩阵U的列是X的标准正交的特征向量，可以把他们看作基向量。并且这些特征向量已经按特征值从大到小排序，我们只需要取指定的前n个特征向量（上述代码n取144）并将X映射过去，就能将X降为相应的n维数据（即Xi由D维降到n维）。</p>\n<p>和PCA类似，还有一种预处理<strong>白化</strong>，它是将X映射到完整的U上并进行标准化（归一化），代码如下：</p>\n<pre><code>Xrot = np.dot(X, U) # decorrelate the data\nXwhite = Xrot / np.sqrt(S + 1e-5) #加1e-5为了防止除0\n</code></pre><p>白化有一个缺点，它将所有特征都变得同样重要，这样会大幅扩大噪声。</p>\n<p><img src=\"http://cs231n.github.io/assets/nn2/prepro2.jpeg\" alt=\"\"><br><strong>左图</strong>是原始数据， <strong>中图</strong>是投影到U上后的数据， <strong>右图</strong>为白化后的数据。</p>\n<hr>\n<p><img src=\"http://cs231n.github.io/assets/nn2/cifar10pca.jpeg\" alt=\"\"><br>上述是用CIFAR-10的图片做实验进行PCA和白化，从左到右：</p>\n<ol>\n<li>原始图片，3072维（32像素宽，32像素高，3通道）</li>\n<li>U中的前144个特征向量，即<code>U[:,:144]</code>,其中每一列表示为一张图片</li>\n<li>PCA降维后还原的图片，代码为<code>Xrot.dot(U.T[:144,:])</code>，3072维</li>\n<li>白化后的图片，低频部分被忽略，高频部分被放大</li>\n</ol>\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p><strong>在CNN中必要的预处理是0均值化，注意0均值化对于训练集、验证集和测试集都是减训练集的均值。</strong></p>\n<h2 id=\"2-权值初始化\"><a href=\"#2-权值初始化\" class=\"headerlink\" title=\"2.权值初始化\"></a>2.权值初始化</h2><p>在训练神经网络之前，我们需要初始化权值矩阵W，而W取什么值是需要考虑的问题。</p>\n<h3 id=\"0值初始化\"><a href=\"#0值初始化\" class=\"headerlink\" title=\"0值初始化\"></a>0值初始化</h3><p>将权值矩阵全部初始化为0是一个误区，如果每个神经元计算出相同的输出，在BP时也会计算出同样的梯度。另外，对于使用ReLU作为激活函数的隐层，输出为0且BP时梯度也都为0，这意味着所有非输入层神经元都死了，学习失败。</p>\n<h3 id=\"随机小数值初始化\"><a href=\"#随机小数值初始化\" class=\"headerlink\" title=\"随机小数值初始化\"></a>随机小数值初始化</h3><p>我们还是希望用接近0的小数值来初始化权值W，一般采用高斯分布的随机数，代码为<code>W = 0.01* np.random.randn(D,H)</code>，W的均值为0。<strong>注意不能用太小的值来初始化W，过小的W会使BP时计算的梯度太小而导致梯度消失。</strong></p>\n<p><strong>用1/sqrt(n)来校正方差</strong>。上述方法的一个问题随机初始化的神经元的输出的方差随着输入的增加而增加，所以我们将权值除以相应神经元的输入个数（证明参见<a href=\"http://cs231n.github.io/neural-networks-2/\" target=\"_blank\" rel=\"external\">原文</a>），网络中的所有神经元都会有相同的输出分布，代码为：<code>w = np.random.randn(n) / sqrt(n)</code>。近期还有<a href=\"https://arxiv.org/abs/1502.01852\" target=\"_blank\" rel=\"external\">研究</a>表明在特定的情况下ReLu神经元建议用<code>w = np.random.randn(n) / sqrt(2.0/n)</code>作为初始权值。</p>\n<h3 id=\"Bias初始化\"><a href=\"#Bias初始化\" class=\"headerlink\" title=\"Bias初始化\"></a>Bias初始化</h3><p>还记得Bias吗？Bias一般初始化为0，实践证明初始化为0.01之类的有时结果很糟。</p>\n<h3 id=\"小结-1\"><a href=\"#小结-1\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p><strong>建议使用ReLu激活并使用<code>w = np.random.randn(n) / sqrt(2.0/n)</code>进行权值初始化。</strong></p>\n<p><strong>另外，最近一项研究可以减轻很多神经网络初始化带来的麻烦，具体内容见<a href=\"https://arxiv.org/abs/1502.03167\" target=\"_blank\" rel=\"external\">Batch Normalization</a>。</strong></p>\n<h2 id=\"3-正则化\"><a href=\"#3-正则化\" class=\"headerlink\" title=\"3.正则化\"></a>3.正则化</h2><p>正则化是一种惩罚模型复杂性的方法，一般用来控制权值W的大小和分布，防止网络训练过拟合。</p>\n<h3 id=\"L2范数\"><a href=\"#L2范数\" class=\"headerlink\" title=\"L2范数\"></a>L2范数</h3><p>L2范数是最常用的正则化处理，Loss函数加上\\(\\frac{1}{2} \\lambda w^2\\)可以直接对权值\\(w\\)进行平方量级的惩罚。系数之所以为\\(\\frac{1}{2}\\)，是因为\\(\\frac{1}{2} \\lambda w^2\\)对于\\(w\\)的梯度可以简单表示为\\(\\lambda w\\)。L2范数对陡峭的权值向量进行很重的惩罚并有利于获得比较分散的权值向量。</p>\n<h3 id=\"L1范数\"><a href=\"#L1范数\" class=\"headerlink\" title=\"L1范数\"></a>L1范数</h3><p>L1范数也是相比较常用的正则化处理，Loss函数加上\\(\\lambda  \\mid w \\mid\\)一样可以对权值\\(w\\)进行惩罚，并有利于获得比较稀疏的权值向量。使用L2范数一般会获得比L1范数更分散且值较小的权值向量，所以L2范数一般比L1范数性能好。</p>\n<h3 id=\"Max-norm-constraints\"><a href=\"#Max-norm-constraints\" class=\"headerlink\" title=\"Max norm constraints\"></a>Max norm constraints</h3><p>Max norm constraints是一种约束权值向量绝对值上限的方式，并用投影梯度下降确保这个约束。在实践中，像往常一样更新参数，然后强制权值\\(w\\)满足\\(\\Vert w \\Vert_2 &lt; c\\)，\\(c\\)一般为3或4。这种方法的性质是即使学习率设置很大也不会发生数值爆炸，因为参数更新永远在一定范围内。</p>\n<h3 id=\"随机失活（Dropout）\"><a href=\"#随机失活（Dropout）\" class=\"headerlink\" title=\"随机失活（Dropout）\"></a>随机失活（Dropout）</h3><p>随机失活是一种Srivastava在<a href=\"http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf\" target=\"_blank\" rel=\"external\">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</a>中提出的简单且非常有效的正则化方法，它对其它方法（L1，L2，Maxnorm）进行补充。在训练时，随机失活保持神经元以概率\\(p\\)（超参数）激活,否则让其死亡（设为0）。</p>\n<p><img src=\"http://cs231n.github.io/assets/nn2/dropout.jpeg\" alt=\"\"></p>\n<p>上图是从<a href=\"http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf\" target=\"_blank\" rel=\"external\">论文</a>中摘下来的，它描述了这种思想。在训练中，随机失活可以理解为从全连接的神经网络中进行取样，在输入数据的基础上只更新被取样的网络。在测试的时候，不采用随机失活，可以理解为是对所有子网络的指数级ensemble（将在下一部分介绍）作一个平均预测。</p>\n<p>Vanilla的一个三层网络的随机失活代码实现如下：</p>\n<pre><code>&quot;&quot;&quot; Vanilla Dropout: 这不是建议的实现方式 (具体的往下看) &quot;&quot;&quot;\n\np = 0.5 # 随机失活的概率\n\ndef train_step(X):\n  &quot;&quot;&quot; X contains the data &quot;&quot;&quot;\n\n  # forward pass for example 3-layer neural network\n  H1 = np.maximum(0, np.dot(W1, X) + b1)\n  U1 = np.random.rand(*H1.shape) &lt; p # 第一隐层输出的失活掩码\n  H1 *= U1 # drop!\n  H2 = np.maximum(0, np.dot(W2, H1) + b2)\n  U2 = np.random.rand(*H2.shape) &lt; p # 第二隐层输出的失活掩码\n  H2 *= U2 # drop!\n  out = np.dot(W3, H2) + b3\n\n  # backward pass: compute gradients... (not shown)\n  # perform parameter update... (not shown)\n\ndef predict(X):\n  # ensembled forward pass\n  H1 = np.maximum(0, np.dot(W1, X) + b1) * p # 将第一隐层输出缩放\n  H2 = np.maximum(0, np.dot(W2, H1) + b2) * p # 将第二隐层输出缩放\n  out = np.dot(W3, H2) + b3\n</code></pre><p>上述代码的train_step函数在第一个隐层和第二个隐层的输出上进行了两次随机失活，当然对输入层的输出X进行随机失活也是可以的。反向传播保持不变，但是当然不得不考虑正向生成的掩码U1和U2。（<strong>如何考虑？</strong>）</p>\n<p>关键是要注意预测函数<code>predict</code>并没有使用任何随机失活，但是将两个隐层的输出按比例\\(p\\)缩放了。这一点很重要，因为在测试阶段所有的神经元是看得到所有的输入的而训练阶段不是，所以我们希望测试阶段的输出和训练阶段的输出保持一致。</p>\n<p>为了不在关键的测试阶段缩放数据，一般采用<strong>反向随机失活</strong>（<strong>inverted dropout</strong>），即在训练阶段使用随机失活后就立即反向缩放数据来还原输出量，代码如下：</p>\n<pre><code>&quot;&quot;&quot; \nInverted Dropout: 这才是建议的实现方式\n在训练阶段反向缩放数据，不用动测试阶段的代码。\n&quot;&quot;&quot;\n\np = 0.5 # 随机失活的概率\n\ndef train_step(X):\n  # forward pass for example 3-layer neural network\n  H1 = np.maximum(0, np.dot(W1, X) + b1)\n  U1 = (np.random.rand(*H1.shape) &lt; p) / p # 第一隐层失活，注意放大了1/p!\n  H1 *= U1 # drop!\n  H2 = np.maximum(0, np.dot(W2, H1) + b2)\n  U2 = (np.random.rand(*H2.shape) &lt; p) / p # 第一隐层失活. 注意放大了1/p!\n  H2 *= U2 # drop!\n  out = np.dot(W3, H2) + b3\n\n  # backward pass: compute gradients... (not shown)\n  # perform parameter update... (not shown)\n\ndef predict(X):\n  # ensembled forward pass\n  H1 = np.maximum(0, np.dot(W1, X) + b1) # 这里没有缩放了！\n  H2 = np.maximum(0, np.dot(W2, H1) + b2) # 这里没有缩放了！\n  out = np.dot(W3, H2) + b3\n</code></pre><h3 id=\"正向传递中的噪声\"><a href=\"#正向传递中的噪声\" class=\"headerlink\" title=\"正向传递中的噪声\"></a>正向传递中的噪声</h3><p>随机失活属于网络正向传递的随机行为中的一般方法中的一种，经过测试，通过这种方法噪声会被边缘化。<a href=\"https://cs.nyu.edu/~wanli/dropc/\" target=\"_blank\" rel=\"external\">DropConnect</a>是这个方面的另一种方法，它在正向传递时用随机数的掩码代替随机失活中的0掩码。在CNN中有很多类似的方法，包括随机采样池化（stochastic pooling）等，将在后续章节介绍。</p>\n<h3 id=\"Bias正则化\"><a href=\"#Bias正则化\" class=\"headerlink\" title=\"Bias正则化\"></a>Bias正则化</h3><p>还记得Bias吗？我们一般不正则化Bias，因为它不与数据交互。</p>\n<h3 id=\"小结-2\"><a href=\"#小结-2\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p><strong>一般最最常用的正则化方式是单独使用L2范数，然后在每层使用\\(p = 0.5\\)的随机失活，\\(p\\)可以使用验证集调整。</strong></p>\n<h2 id=\"4-损失函数（Loss-functions）\"><a href=\"#4-损失函数（Loss-functions）\" class=\"headerlink\" title=\"4.损失函数（Loss functions）\"></a>4.损失函数（Loss functions）</h2><p>损失函数是一个监督学习的问题，用来衡量预测和真实标签的匹配度。整体的数据损失是每个样本损失的均值，\\(L = \\frac{1}{N} \\sum_i L_i\\)，N是训练样本数。我们将输出层的激活函数简写为\\(f = f(x_i; W)\\)，接下来我们讨论一些问题：</p>\n<h3 id=\"分类\"><a href=\"#分类\" class=\"headerlink\" title=\"分类\"></a>分类</h3><p>假设数据集中每个样本只有一个正确的标签，一个最常用的损失函数是SVM分类器使用的铰链损失（hinge loss）：<br>$$L_i = \\sum_{j\\neq y_i} \\max(0, f_j - f_{y_i} + 1)$$<br>有些报道称用平方铰链损失（squared hinge loss）\\(\\max(0, f_j - f_{y_i} + 1)^2\\)具有更好的性能。另一种常用的损失函数是Softmax分类器使用的交叉熵损失（cross-entropy loss）：<br>$$L<em>i = -\\log\\left(\\frac{e^{f\\</em>{y_i}}}{ \\sum_j e^{f_j} }\\right)$$</p>\n<h3 id=\"问题：大量的类别\"><a href=\"#问题：大量的类别\" class=\"headerlink\" title=\"问题：大量的类别\"></a>问题：大量的类别</h3><p>当标签种类非常多（例如字典里的词数或者ImageNet中的22000个图片类别）时，可能需要用到分层Softmax(Hierarchical Softmax)。分层Softmax将所有类别标签分解到一棵二叉树中，每一个类别标签表示为树上的一条路径，详细的内容见将其<a href=\"https://arxiv.org/pdf/1310.4546.pdf\" target=\"_blank\" rel=\"external\">应用于Word2Vec的论文</a>。</p>\n<h3 id=\"属性分类\"><a href=\"#属性分类\" class=\"headerlink\" title=\"属性分类\"></a>属性分类</h3><p>输出向量不是含有每个样本的单个的类别标签，而是含有每个样本中所具有的多个属性标签，比如说Instagram上的一张图片含有多个关键字。一种明智的做法是为每一个属性创建一个独立的二分类器：<br>$$L_i = \\sum_j \\max(0, 1 - y_{ij} f_j)$$<br>上式中\\(j\\)为属性种类，\\(y_{ij}\\)为标签，表示\\(i\\)样本是否具有\\(j\\)属性，取值为+1或-1。\\(f_j\\)为预测值，正值表示预测具有\\(j\\)属性，否则不具有\\(j\\)属性。</p>\n<p>另一种可选的方法是为每个属性单独的训练一个逻辑回归（logistic regression）分类器。一个二元逻辑回归分类器只拥有两个类别（0,1），然后计算类别1的概率：<br>$$P(y = 1 \\mid x; w, b) = \\frac{1}{1 + e^{-(w^Tx +b)}} = \\sigma (w^Tx + b)$$<br>因为类别1和类别0的概率之和为1，所以类别0的概率为\\(P(y = 0 \\mid x; w, b) = 1 - P(y = 1 \\mid x; w,b)\\)。当\\(\\sigma (w^Tx + b) &gt; 0.5\\)或\\(w^Tx +b &gt; 0\\)时样本为正例，即分类为1。损失函数为：<br>$$L_i = - \\sum_j y_{ij} \\log(\\sigma(f_j)) + (1 - y_{ij}) \\log(1 - \\sigma(f_j))$$<br>损失函数对\\(f\\)求导结果非常简单 \\(\\partial{L_i} / \\partial{f_j} = y_{ij} - \\sigma(f_j)\\)。</p>\n<h3 id=\"回归（Regression）\"><a href=\"#回归（Regression）\" class=\"headerlink\" title=\"回归（Regression）\"></a>回归（Regression）</h3><p>回归是预测连续实值的任务，比如预测房价。在这种任务中，损失函数一般计算预测值和实际值差值的L2范数平方或L1范数。使用L2范数平方的损失函数表示为：<br>$$L_i = \\Vert f - y_i \\Vert_2^2$$<br>之所以用L2范数平方是因为求梯度简单。<strong>注意回归问题比分类问题难优化的多，处理回归问题应该最先考虑是否能转化为分类问题。</strong></p>\n<p>###小节###<br><strong>在每类任务中采用最常用的损失函数</strong></p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><ul>\n<li><strong>对数据X进行0均值化处理</strong></li>\n<li><strong>使用<code>w = np.random.randn(n) * sqrt(2.0/n)</code>初始化权值W，n为输入变量个数</strong></li>\n<li><strong>使用L2范数正则化并采用反向随机失活</strong></li>\n<li><strong>使用batch normalization</strong></li>\n<li><strong>在每类任务中采用最常用的损失函数</strong></li>\n</ul>\n<hr>\n<p>© 2018 by 0ne.tech</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"神经网络-第2部分：设置Data和Loss\"><a href=\"#神经网络-第2部分：设置Data和Loss\" class=\"headerlink\" title=\"神经网络 第2部分：设置Data和Loss\"></a><a href=\"http://cs231n.github.io/neural-networks-2/\" target=\"_blank\" rel=\"external\">神经网络 第2部分：设置Data和Loss</a></h2><p>这一部分主要讨论神经网络中一些数据的设置原则，包括：</p>\n<ol>\n<li><strong>数据X的预处理</strong></li>\n<li><strong>权值W的初始化</strong></li>\n<li><strong>正则化</strong></li>\n<li><strong>损失函数Loss的选择</strong></li>\n</ol>\n<h2 id=\"1-数据预处理\"><a href=\"#1-数据预处理\" class=\"headerlink\" title=\"1.数据预处理\"></a>1.数据预处理</h2><h3 id=\"0均值化\"><a href=\"#0均值化\" class=\"headerlink\" title=\"0均值化\"></a>0均值化</h3><p><strong>0均值化</strong>是将数据调整为以0为中心的处理。</p>\n<p>最常见的数据预处理，将数据Xi中每一维的数据都减去这一维的均值，代码为：<code>X -= np.mean(X, axis = 0)</code>。</p>\n<p>对于图片数据来说，因为X中的值都在0与255之间，可以直接减去整个整个X的均值，代码为：<code>X -= np.mean(X)</code>。</p>\n<h3 id=\"标准化\"><a href=\"#标准化\" class=\"headerlink\" title=\"标准化\"></a>标准化</h3><p><strong>标准化</strong>是将数据按比例缩放，使之落入一个小的特定区间。</p>\n<p>一种方法是将已经0均值化的数据除以它的标准差，代码为：<code>X /= np.std(X, axis = 0)</code>，这个处理将数据分布调整到-1和1之间。</p>\n<p>标准化只对每一个维度范围不一样数据有意义，对图片这种每一个像素值都在0到255的数据，不是必须的处理。</p>\n<p><img src=\"http://cs231n.github.io/assets/nn2/prepro1.jpeg\" alt=\"\"><br><strong>左图</strong>是原始数据， <strong>中图</strong>是0均值化后的数据， <strong>右图</strong>为标准化后的数据。</p>\n<h3 id=\"主成份分析-PCA\"><a href=\"#主成份分析-PCA\" class=\"headerlink\" title=\"主成份分析(PCA)\"></a>主成份分析(PCA)</h3><p><strong>主成分分析</strong>主要用于数据降维，保留数据的主要特征。</p>\n<p>PCA的处理流程为：</p>\n<ol>\n<li>对数据X进行0均值化</li>\n<li>计算X的协方差矩阵</li>\n<li>对协方差矩阵进行奇异值分解（SVD）</li>\n<li>使用特征矩阵对数据X进行降维</li>\n</ol>\n<p>具体代码大致如下：</p>\n<pre><code># 假设X的shape为 N by D\nX -= np.mean(X, axis = 0)             # 0均值化（必须）\ncov = np.dot(X.T, X) / X.shape[0]     # 计算协方差矩阵\nU,S,V = np.linalg.svd(cov)             # 奇异值分解，S为奇异向量\nXrot_reduced = np.dot(X, U[:,:144]) # 将X降到144维\n</code></pre><p>矩阵U的列是X的标准正交的特征向量，可以把他们看作基向量。并且这些特征向量已经按特征值从大到小排序，我们只需要取指定的前n个特征向量（上述代码n取144）并将X映射过去，就能将X降为相应的n维数据（即Xi由D维降到n维）。</p>\n<p>和PCA类似，还有一种预处理<strong>白化</strong>，它是将X映射到完整的U上并进行标准化（归一化），代码如下：</p>\n<pre><code>Xrot = np.dot(X, U) # decorrelate the data\nXwhite = Xrot / np.sqrt(S + 1e-5) #加1e-5为了防止除0\n</code></pre><p>白化有一个缺点，它将所有特征都变得同样重要，这样会大幅扩大噪声。</p>\n<p><img src=\"http://cs231n.github.io/assets/nn2/prepro2.jpeg\" alt=\"\"><br><strong>左图</strong>是原始数据， <strong>中图</strong>是投影到U上后的数据， <strong>右图</strong>为白化后的数据。</p>\n<hr>\n<p><img src=\"http://cs231n.github.io/assets/nn2/cifar10pca.jpeg\" alt=\"\"><br>上述是用CIFAR-10的图片做实验进行PCA和白化，从左到右：</p>\n<ol>\n<li>原始图片，3072维（32像素宽，32像素高，3通道）</li>\n<li>U中的前144个特征向量，即<code>U[:,:144]</code>,其中每一列表示为一张图片</li>\n<li>PCA降维后还原的图片，代码为<code>Xrot.dot(U.T[:144,:])</code>，3072维</li>\n<li>白化后的图片，低频部分被忽略，高频部分被放大</li>\n</ol>\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p><strong>在CNN中必要的预处理是0均值化，注意0均值化对于训练集、验证集和测试集都是减训练集的均值。</strong></p>\n<h2 id=\"2-权值初始化\"><a href=\"#2-权值初始化\" class=\"headerlink\" title=\"2.权值初始化\"></a>2.权值初始化</h2><p>在训练神经网络之前，我们需要初始化权值矩阵W，而W取什么值是需要考虑的问题。</p>\n<h3 id=\"0值初始化\"><a href=\"#0值初始化\" class=\"headerlink\" title=\"0值初始化\"></a>0值初始化</h3><p>将权值矩阵全部初始化为0是一个误区，如果每个神经元计算出相同的输出，在BP时也会计算出同样的梯度。另外，对于使用ReLU作为激活函数的隐层，输出为0且BP时梯度也都为0，这意味着所有非输入层神经元都死了，学习失败。</p>\n<h3 id=\"随机小数值初始化\"><a href=\"#随机小数值初始化\" class=\"headerlink\" title=\"随机小数值初始化\"></a>随机小数值初始化</h3><p>我们还是希望用接近0的小数值来初始化权值W，一般采用高斯分布的随机数，代码为<code>W = 0.01* np.random.randn(D,H)</code>，W的均值为0。<strong>注意不能用太小的值来初始化W，过小的W会使BP时计算的梯度太小而导致梯度消失。</strong></p>\n<p><strong>用1/sqrt(n)来校正方差</strong>。上述方法的一个问题随机初始化的神经元的输出的方差随着输入的增加而增加，所以我们将权值除以相应神经元的输入个数（证明参见<a href=\"http://cs231n.github.io/neural-networks-2/\" target=\"_blank\" rel=\"external\">原文</a>），网络中的所有神经元都会有相同的输出分布，代码为：<code>w = np.random.randn(n) / sqrt(n)</code>。近期还有<a href=\"https://arxiv.org/abs/1502.01852\" target=\"_blank\" rel=\"external\">研究</a>表明在特定的情况下ReLu神经元建议用<code>w = np.random.randn(n) / sqrt(2.0/n)</code>作为初始权值。</p>\n<h3 id=\"Bias初始化\"><a href=\"#Bias初始化\" class=\"headerlink\" title=\"Bias初始化\"></a>Bias初始化</h3><p>还记得Bias吗？Bias一般初始化为0，实践证明初始化为0.01之类的有时结果很糟。</p>\n<h3 id=\"小结-1\"><a href=\"#小结-1\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p><strong>建议使用ReLu激活并使用<code>w = np.random.randn(n) / sqrt(2.0/n)</code>进行权值初始化。</strong></p>\n<p><strong>另外，最近一项研究可以减轻很多神经网络初始化带来的麻烦，具体内容见<a href=\"https://arxiv.org/abs/1502.03167\" target=\"_blank\" rel=\"external\">Batch Normalization</a>。</strong></p>\n<h2 id=\"3-正则化\"><a href=\"#3-正则化\" class=\"headerlink\" title=\"3.正则化\"></a>3.正则化</h2><p>正则化是一种惩罚模型复杂性的方法，一般用来控制权值W的大小和分布，防止网络训练过拟合。</p>\n<h3 id=\"L2范数\"><a href=\"#L2范数\" class=\"headerlink\" title=\"L2范数\"></a>L2范数</h3><p>L2范数是最常用的正则化处理，Loss函数加上\\(\\frac{1}{2} \\lambda w^2\\)可以直接对权值\\(w\\)进行平方量级的惩罚。系数之所以为\\(\\frac{1}{2}\\)，是因为\\(\\frac{1}{2} \\lambda w^2\\)对于\\(w\\)的梯度可以简单表示为\\(\\lambda w\\)。L2范数对陡峭的权值向量进行很重的惩罚并有利于获得比较分散的权值向量。</p>\n<h3 id=\"L1范数\"><a href=\"#L1范数\" class=\"headerlink\" title=\"L1范数\"></a>L1范数</h3><p>L1范数也是相比较常用的正则化处理，Loss函数加上\\(\\lambda  \\mid w \\mid\\)一样可以对权值\\(w\\)进行惩罚，并有利于获得比较稀疏的权值向量。使用L2范数一般会获得比L1范数更分散且值较小的权值向量，所以L2范数一般比L1范数性能好。</p>\n<h3 id=\"Max-norm-constraints\"><a href=\"#Max-norm-constraints\" class=\"headerlink\" title=\"Max norm constraints\"></a>Max norm constraints</h3><p>Max norm constraints是一种约束权值向量绝对值上限的方式，并用投影梯度下降确保这个约束。在实践中，像往常一样更新参数，然后强制权值\\(w\\)满足\\(\\Vert w \\Vert_2 &lt; c\\)，\\(c\\)一般为3或4。这种方法的性质是即使学习率设置很大也不会发生数值爆炸，因为参数更新永远在一定范围内。</p>\n<h3 id=\"随机失活（Dropout）\"><a href=\"#随机失活（Dropout）\" class=\"headerlink\" title=\"随机失活（Dropout）\"></a>随机失活（Dropout）</h3><p>随机失活是一种Srivastava在<a href=\"http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf\" target=\"_blank\" rel=\"external\">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</a>中提出的简单且非常有效的正则化方法，它对其它方法（L1，L2，Maxnorm）进行补充。在训练时，随机失活保持神经元以概率\\(p\\)（超参数）激活,否则让其死亡（设为0）。</p>\n<p><img src=\"http://cs231n.github.io/assets/nn2/dropout.jpeg\" alt=\"\"></p>\n<p>上图是从<a href=\"http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf\" target=\"_blank\" rel=\"external\">论文</a>中摘下来的，它描述了这种思想。在训练中，随机失活可以理解为从全连接的神经网络中进行取样，在输入数据的基础上只更新被取样的网络。在测试的时候，不采用随机失活，可以理解为是对所有子网络的指数级ensemble（将在下一部分介绍）作一个平均预测。</p>\n<p>Vanilla的一个三层网络的随机失活代码实现如下：</p>\n<pre><code>&quot;&quot;&quot; Vanilla Dropout: 这不是建议的实现方式 (具体的往下看) &quot;&quot;&quot;\n\np = 0.5 # 随机失活的概率\n\ndef train_step(X):\n  &quot;&quot;&quot; X contains the data &quot;&quot;&quot;\n\n  # forward pass for example 3-layer neural network\n  H1 = np.maximum(0, np.dot(W1, X) + b1)\n  U1 = np.random.rand(*H1.shape) &lt; p # 第一隐层输出的失活掩码\n  H1 *= U1 # drop!\n  H2 = np.maximum(0, np.dot(W2, H1) + b2)\n  U2 = np.random.rand(*H2.shape) &lt; p # 第二隐层输出的失活掩码\n  H2 *= U2 # drop!\n  out = np.dot(W3, H2) + b3\n\n  # backward pass: compute gradients... (not shown)\n  # perform parameter update... (not shown)\n\ndef predict(X):\n  # ensembled forward pass\n  H1 = np.maximum(0, np.dot(W1, X) + b1) * p # 将第一隐层输出缩放\n  H2 = np.maximum(0, np.dot(W2, H1) + b2) * p # 将第二隐层输出缩放\n  out = np.dot(W3, H2) + b3\n</code></pre><p>上述代码的train_step函数在第一个隐层和第二个隐层的输出上进行了两次随机失活，当然对输入层的输出X进行随机失活也是可以的。反向传播保持不变，但是当然不得不考虑正向生成的掩码U1和U2。（<strong>如何考虑？</strong>）</p>\n<p>关键是要注意预测函数<code>predict</code>并没有使用任何随机失活，但是将两个隐层的输出按比例\\(p\\)缩放了。这一点很重要，因为在测试阶段所有的神经元是看得到所有的输入的而训练阶段不是，所以我们希望测试阶段的输出和训练阶段的输出保持一致。</p>\n<p>为了不在关键的测试阶段缩放数据，一般采用<strong>反向随机失活</strong>（<strong>inverted dropout</strong>），即在训练阶段使用随机失活后就立即反向缩放数据来还原输出量，代码如下：</p>\n<pre><code>&quot;&quot;&quot; \nInverted Dropout: 这才是建议的实现方式\n在训练阶段反向缩放数据，不用动测试阶段的代码。\n&quot;&quot;&quot;\n\np = 0.5 # 随机失活的概率\n\ndef train_step(X):\n  # forward pass for example 3-layer neural network\n  H1 = np.maximum(0, np.dot(W1, X) + b1)\n  U1 = (np.random.rand(*H1.shape) &lt; p) / p # 第一隐层失活，注意放大了1/p!\n  H1 *= U1 # drop!\n  H2 = np.maximum(0, np.dot(W2, H1) + b2)\n  U2 = (np.random.rand(*H2.shape) &lt; p) / p # 第一隐层失活. 注意放大了1/p!\n  H2 *= U2 # drop!\n  out = np.dot(W3, H2) + b3\n\n  # backward pass: compute gradients... (not shown)\n  # perform parameter update... (not shown)\n\ndef predict(X):\n  # ensembled forward pass\n  H1 = np.maximum(0, np.dot(W1, X) + b1) # 这里没有缩放了！\n  H2 = np.maximum(0, np.dot(W2, H1) + b2) # 这里没有缩放了！\n  out = np.dot(W3, H2) + b3\n</code></pre><h3 id=\"正向传递中的噪声\"><a href=\"#正向传递中的噪声\" class=\"headerlink\" title=\"正向传递中的噪声\"></a>正向传递中的噪声</h3><p>随机失活属于网络正向传递的随机行为中的一般方法中的一种，经过测试，通过这种方法噪声会被边缘化。<a href=\"https://cs.nyu.edu/~wanli/dropc/\" target=\"_blank\" rel=\"external\">DropConnect</a>是这个方面的另一种方法，它在正向传递时用随机数的掩码代替随机失活中的0掩码。在CNN中有很多类似的方法，包括随机采样池化（stochastic pooling）等，将在后续章节介绍。</p>\n<h3 id=\"Bias正则化\"><a href=\"#Bias正则化\" class=\"headerlink\" title=\"Bias正则化\"></a>Bias正则化</h3><p>还记得Bias吗？我们一般不正则化Bias，因为它不与数据交互。</p>\n<h3 id=\"小结-2\"><a href=\"#小结-2\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p><strong>一般最最常用的正则化方式是单独使用L2范数，然后在每层使用\\(p = 0.5\\)的随机失活，\\(p\\)可以使用验证集调整。</strong></p>\n<h2 id=\"4-损失函数（Loss-functions）\"><a href=\"#4-损失函数（Loss-functions）\" class=\"headerlink\" title=\"4.损失函数（Loss functions）\"></a>4.损失函数（Loss functions）</h2><p>损失函数是一个监督学习的问题，用来衡量预测和真实标签的匹配度。整体的数据损失是每个样本损失的均值，\\(L = \\frac{1}{N} \\sum_i L_i\\)，N是训练样本数。我们将输出层的激活函数简写为\\(f = f(x_i; W)\\)，接下来我们讨论一些问题：</p>\n<h3 id=\"分类\"><a href=\"#分类\" class=\"headerlink\" title=\"分类\"></a>分类</h3><p>假设数据集中每个样本只有一个正确的标签，一个最常用的损失函数是SVM分类器使用的铰链损失（hinge loss）：<br>$$L_i = \\sum_{j\\neq y_i} \\max(0, f_j - f_{y_i} + 1)$$<br>有些报道称用平方铰链损失（squared hinge loss）\\(\\max(0, f_j - f_{y_i} + 1)^2\\)具有更好的性能。另一种常用的损失函数是Softmax分类器使用的交叉熵损失（cross-entropy loss）：<br>$$L<em>i = -\\log\\left(\\frac{e^{f\\</em>{y_i}}}{ \\sum_j e^{f_j} }\\right)$$</p>\n<h3 id=\"问题：大量的类别\"><a href=\"#问题：大量的类别\" class=\"headerlink\" title=\"问题：大量的类别\"></a>问题：大量的类别</h3><p>当标签种类非常多（例如字典里的词数或者ImageNet中的22000个图片类别）时，可能需要用到分层Softmax(Hierarchical Softmax)。分层Softmax将所有类别标签分解到一棵二叉树中，每一个类别标签表示为树上的一条路径，详细的内容见将其<a href=\"https://arxiv.org/pdf/1310.4546.pdf\" target=\"_blank\" rel=\"external\">应用于Word2Vec的论文</a>。</p>\n<h3 id=\"属性分类\"><a href=\"#属性分类\" class=\"headerlink\" title=\"属性分类\"></a>属性分类</h3><p>输出向量不是含有每个样本的单个的类别标签，而是含有每个样本中所具有的多个属性标签，比如说Instagram上的一张图片含有多个关键字。一种明智的做法是为每一个属性创建一个独立的二分类器：<br>$$L_i = \\sum_j \\max(0, 1 - y_{ij} f_j)$$<br>上式中\\(j\\)为属性种类，\\(y_{ij}\\)为标签，表示\\(i\\)样本是否具有\\(j\\)属性，取值为+1或-1。\\(f_j\\)为预测值，正值表示预测具有\\(j\\)属性，否则不具有\\(j\\)属性。</p>\n<p>另一种可选的方法是为每个属性单独的训练一个逻辑回归（logistic regression）分类器。一个二元逻辑回归分类器只拥有两个类别（0,1），然后计算类别1的概率：<br>$$P(y = 1 \\mid x; w, b) = \\frac{1}{1 + e^{-(w^Tx +b)}} = \\sigma (w^Tx + b)$$<br>因为类别1和类别0的概率之和为1，所以类别0的概率为\\(P(y = 0 \\mid x; w, b) = 1 - P(y = 1 \\mid x; w,b)\\)。当\\(\\sigma (w^Tx + b) &gt; 0.5\\)或\\(w^Tx +b &gt; 0\\)时样本为正例，即分类为1。损失函数为：<br>$$L_i = - \\sum_j y_{ij} \\log(\\sigma(f_j)) + (1 - y_{ij}) \\log(1 - \\sigma(f_j))$$<br>损失函数对\\(f\\)求导结果非常简单 \\(\\partial{L_i} / \\partial{f_j} = y_{ij} - \\sigma(f_j)\\)。</p>\n<h3 id=\"回归（Regression）\"><a href=\"#回归（Regression）\" class=\"headerlink\" title=\"回归（Regression）\"></a>回归（Regression）</h3><p>回归是预测连续实值的任务，比如预测房价。在这种任务中，损失函数一般计算预测值和实际值差值的L2范数平方或L1范数。使用L2范数平方的损失函数表示为：<br>$$L_i = \\Vert f - y_i \\Vert_2^2$$<br>之所以用L2范数平方是因为求梯度简单。<strong>注意回归问题比分类问题难优化的多，处理回归问题应该最先考虑是否能转化为分类问题。</strong></p>\n<p>###小节###<br><strong>在每类任务中采用最常用的损失函数</strong></p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><ul>\n<li><strong>对数据X进行0均值化处理</strong></li>\n<li><strong>使用<code>w = np.random.randn(n) * sqrt(2.0/n)</code>初始化权值W，n为输入变量个数</strong></li>\n<li><strong>使用L2范数正则化并采用反向随机失活</strong></li>\n<li><strong>使用batch normalization</strong></li>\n<li><strong>在每类任务中采用最常用的损失函数</strong></li>\n</ul>\n<hr>\n<p>© 2018 by 0ne.tech</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cjhq2z7qr0000p8vjfzvnel5l","category_id":"cjhq2z7r60002p8vjzqpx8uu8","_id":"cjhq2z7re0005p8vjuw7dypgg"},{"post_id":"cjhq31uc40000m0vji7e5d6c7","category_id":"cjhq31ucl0001m0vjpeexd1je","_id":"cjhq31ucq0004m0vj07u2runn"}],"PostTag":[{"post_id":"cjhq2z7qr0000p8vjfzvnel5l","tag_id":"cjhq2z7r90003p8vj8cpkajf5","_id":"cjhq2z7rc0004p8vjr9dap2xc"},{"post_id":"cjhq31uc40000m0vji7e5d6c7","tag_id":"cjhq31uco0002m0vjqayurjsn","_id":"cjhq31ucr0006m0vjyyi5l9fy"},{"post_id":"cjhq31uc40000m0vji7e5d6c7","tag_id":"cjhq31ucp0003m0vjj6btewqh","_id":"cjhq31ucs0007m0vjvl4wbmcb"},{"post_id":"cjhq31uc40000m0vji7e5d6c7","tag_id":"cjhq31ucq0005m0vj6p7mvn99","_id":"cjhq31ucs0008m0vjdftfan4l"}],"Tag":[{"name":"study","_id":"cjhq2z7r90003p8vj8cpkajf5"},{"name":"Machine Learning","_id":"cjhq31uco0002m0vjqayurjsn"},{"name":"Deep Learning","_id":"cjhq31ucp0003m0vjj6btewqh"},{"name":"CS231n","_id":"cjhq31ucq0005m0vj6p7mvn99"}]}}